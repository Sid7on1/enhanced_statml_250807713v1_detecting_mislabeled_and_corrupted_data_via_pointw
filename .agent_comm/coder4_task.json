{
  "agent_id": "coder4",
  "task_id": "task_3",
  "files": [
    {
      "name": "augmentation.py",
      "purpose": "Data augmentation techniques",
      "priority": "medium"
    },
    {
      "name": "feature_extraction.py",
      "purpose": "Feature extraction layers",
      "priority": "medium"
    }
  ],
  "project_info": {
    "project_name": "enhanced_stat.ML_2508.07713v1_Detecting_Mislabeled_and_Corrupted_Data_via_Pointw",
    "project_type": "computer_vision",
    "description": "Enhanced AI project based on stat.ML_2508.07713v1_Detecting-Mislabeled-and-Corrupted-Data-via-Pointw with content analysis. Detected project type: computer vision (confidence score: 9 matches).",
    "key_algorithms": [
      "Correction",
      "Selection",
      "During",
      "Language",
      "Improve",
      "Enabling",
      "How",
      "Noise",
      "Through",
      "Chine"
    ],
    "main_libraries": [
      "torch",
      "numpy",
      "pandas"
    ]
  },
  "paper_content": "PDF: stat.ML_2508.07713v1_Detecting-Mislabeled-and-Corrupted-Data-via-Pointw.pdf\nChunk: 1/1\n==================================================\n\n--- Page 1 ---\nDetecting Mislabeled and Corrupted Data via Pointwise Mutual Information\nJinghan Yang, Jiayu Weng\nInstitute of Data Science\nThe University of Hong Kong\nAbstract\nDeep neural networks can memorize corrupted labels, mak-\ning data quality critical for model performance, yet real-\nworld datasets are frequently compromised by both la-\nbel noise and input noise. This paper proposes a mutual\ninformation-based framework for data selection under hy-\nbrid noise scenarios that quantifies statistical dependen-\ncies between inputs and labels. We compute each sample\u2019s\npointwise contribution to the overall mutual information\nand find that lower contributions indicate noisy or misla-\nbeled instances. Empirical validation on MNIST with dif-\nferent synthetic noise settings demonstrates that the method\neffectively filters low-quality samples. Under label corrup-\ntion, training on high-MI samples improves classification\naccuracy by up to 15% compared to random sampling. Fur-\nthermore, the method exhibits robustness to benign input\nmodifications, preserving semantically valid data while fil-\ntering truly corrupted samples1.\n1. Introduction\nThe advancement of large-scale datasets has enabled deep\nneural networks to achieve remarkable success across ma-\nchine learning domains including computer vision [16, 29],\ninformation retrieval [25, 26, 47], and natural language pro-\ncessing [4, 11, 30]. However, this success fundamentally\ndepends on access to high-quality, accurately annotated\ndata\u2014a resource that demands significant financial and\ntemporal investment. In practice, annotation quality is fre-\nquently compromised. Crowdsourcing platforms and con-\ntextual labeling methods, while cost-effective, often yield\ninconsistent annotations [24, 27]. Even domain experts pro-\nduce variable labels when facing complex tasks [5, 21],\nand adversarial actors may deliberately corrupt labels [40].\nThese factors produce noisy labels\u2014annotations that devi-\nate from true class assignments. Empirical studies reveal\nconcerning contamination rates in real-world datasets, rang-\ning ranging from 8.0% in ANIMAL-10N to 38.5% in Cloth-\n1Preprinting1M [17, 19, 33, 41]. Such noise significantly degrades\nmodel robustness and generalization [34, 45], making the\nidentification and removal of corrupted samples crucial for\nmaintaining model performance.\nExisting approaches to handle noisy labels typically fall\ninto two categories: (1) noise-robust training methods that\nmodify loss functions or training procedures [28, 36, 48],\nand (2) sample selection methods that identify and remove\ncorrupted instances [7, 12, 18]. While the former requires\narchitectural changes and often assumes specific noise mod-\nels, the latter offers a more general solution but typically re-\nlies on model-specific signals like loss values or gradients,\nlimiting their applicability across different architectures.\nWe propose using Mutual Information (MI) between in-\nputs and labels as a metric to identify noisy data points. MI\nquantifies statistical dependency by measuring how much\nknowing one variable reduces uncertainty about another\n[31]. Intuitively, clean samples exhibit strong statistical\nalignment between features and labels, while corrupted\nsamples show weaker dependencies. By computing point-\nwise mutual information (PMI) for each sample\u2014which\nmeasures how much more likely a specific input-label pair\noccurs together compared to random chance\u2014we can sys-\ntematically identify and exclude low-quality data. We em-\nploy the Kraskov-St \u00a8ogbauer-Grassberger (KSG) estimator\n[8, 15] to approximate these values directly from data with-\nout requiring true probability distributions.\nOur MI-based selection offers three key advantages.\nFirst, it effectively detects label noise: corrupted labels pro-\nduce flattened MI score distributions with reduced inter-\nclass variance, making unreliable samples distinguishable.\nSecond, it maintains robustness to benign input perturba-\ntions (e.g., mild blur or occlusion) that preserve semantic\ncontent, ensuring we don\u2019t discard valuable but imperfect\ndata. Third, it operates in a model-agnostic manner without\nrequiring gradient or loss signals, enabling broad applica-\nbility across architectures and domains.\nThis work addresses two fundamental questions: (1)\nHow does noise affect MI attribution scores, and can these\nscores reliably identify mislabeled samples? (2) Does MI-\nbased selection improve model performance compared toarXiv:2508.07713v1  [cs.LG]  11 Aug 2025\n\n--- Page 2 ---\n(a) (b) (c) (d)Figure 1. Mutual information (MI) score distributions across digit labels under increasing label noise. (a) Original clean dataset. (b)\nCorruption rate of 0.2 with randomly flipped labels. (c) Corruption rate of 0.5. (d) Corruption rate of 0.8. Each point in the graph\nrepresents a sample and is colored according to its MI Score.\nrandom sampling from noisy datasets? Through experi-\nments on MNIST with synthetic noise, we demonstrate that\nMI scores strongly correlate with annotation reliability and\nenable effective data curation even under severe label cor-\nruption.\n2. Method\n2.1. Mutual Information for Data Quality Assess-\nment\nIn supervised learning, training data quality fundamentally\ndepends on how well inputs encode information about their\nlabels. We propose using Mutual Information (MI) to quan-\ntify this relationship and identify problematic data points.\nMI measures the statistical dependence between two vari-\nables\u2014in our case, inputs Xand labels Y. Intuitively, it an-\nswers: \u201dHow much does knowing the input tell us about the\nlabel, and vice versa?\u201d For clean data, we expect high MI\nbetween correctly matched input-label pairs. Conversely,\nmislabeled or noisy data should exhibit low MI, as the cor-\nrupted associations weaken the statistical relationship. For-\nmally, MI can be expressed through entropy\u2014a measure of\nuncertainty in a random variable. For inputs Xand labels\nY:\nI(X;Y) =H(Y)\u2212H(Y|X) =H(X)\u2212H(X|Y),(1)\nwhere H(Y)is the entropy of labels and H(Y|X)is the\nconditional entropy of labels given inputs. This formulation\nreveals MI as the reduction in uncertainty about one variable\nwhen the other is known. For practical computation, MI can\nbe written as:\nI(X;Y) =X\nx\u2208XX\ny\u2208YP(x, y) log\u0012P(x, y)\nP(x)P(y)\u0013\n,(2)\nwhere the term logP(x,y)\nP(x)P(y)represents the pointwise mu-\ntual information (PMI) for each (x, y)pair. While global MI\ncharacterizes the overall dataset quality, identifying specificproblematic samples requires decomposing this global mea-\nsure into local contributions. Each data point (xi, yi)con-\ntributes differently to the total MI\u2014clean samples reinforce\nthe statistical dependence while noisy samples weaken it.\nThis motivates our key insight: by quantifying each point\u2019s\ncontribution to the global MI, we can identify and remove\nsamples that degrade data quality. However, this requires:\nPractical estimation: Real-world datasets lack known prob-\nability distributions Local decomposition: Attribution of MI\nto individual data points\n2.2. The KSG Estimator: A Practical Solution\nThe Kraskov-St \u00a8ogbauer-Grassberger (KSG) estimator [15]\nelegantly addresses both challenges. It provides a non-\nparametric method to estimate MI directly from data while\nnaturally decomposing it into local contributions. For a\ndataset of Ninput-label pairs (xi, yi)N\ni=1, KSG defines the\nlocal MI contribution of each point as:\nI(xi;yi) =\u03c8(k) +\u03c8(N)\u2212\u03c8(nx(i) + 1)\u2212\u03c8(ny(i) + 1) ,\n(3)\nwhere: \u03c8(\u00b7)is the digamma function kis the number\nof nearest neighbors (hyperparameter) nx(i)andny(i)\ncount neighbors in the marginal spaces The global MI\nequals the average of local contributions: I(X;Y) =\n1\nNPN\ni=1I(xi;yi)\nThe local MI contribution I(xi;yi)has a clear geomet-\nric interpretation that directly informs data quality: High\nI(xi;yi): The point has many neighbors in the joint (X, Y )\nspace but few in the marginal spaces. This indicates strong\nlocal coupling\u2014the input strongly predicts its label. Exam-\nple: a clear \u201c7\u201d image surrounded by other correctly labeled\n\u201c7\u201ds. Low/negative I(xi;yi): The point has similar neigh-\nbor densities in joint and marginal spaces, indicating weak\ncoupling. This suggests the input provides little information\nabout its label. Example: a mislabeled or corrupted image\nwhose features appear across multiple classes. By ranking\npoints by their local MI contributions and removing those\nwith the lowest scores, we systematically eliminate sam-\n\n--- Page 3 ---\n(a) (b)Figure 2. MI-based sample selection results under moderate label noise. (a) MI score distribution for the clean dataset (top) and the\ncorrupted dataset with noise rate 0.05 (bottom). Red crosses indicate mislabelled samples. (b) Accuracy on the test set for different\nselection strategies as the percentage of retained training data varies. We compare selection based on global MI, class-wise MI, and\nrandom sampling.\nples that fail to encode meaningful input-label relationships,\nthereby improving overall data quality.\n3. Experiment\nTo validate the effectiveness of mutual information as a\nprincipled metric for identifying and filtering noisy train-\ning data, we design controlled experiments on the MNIST\ndataset with systematically introduced corruptions.\n3.1. Experiment Setup\nDataset We conduct experiments on the MNIST dataset,\na benchmark for handwritten digit classification containing\n60,000 training and 10,000 test grayscale images (28\u00d728\npixels) across 10 digit classes (0\u20139). While MNIST is in-\nherently clean, we introduce controlled synthetic noise to\nevaluate MI-based selection under realistic data quality con-\nditions.\nModel and MI Computation We use logistic regression\nas our classifier for its simplicity and interpretability. To\naddress the high dimensionality of raw images for MI es-\ntimation, we employ a Variational Autoencoder (V AE) to\ncompress the data into a lower-dimensional latent space [8].\nMutual information scores are computed in the V AE latent\nspace between input representations and their correspond-\ning labels.\nNoise Injection To systematically evaluate MI\u2019s discrim-\ninative capabilities, we introduce two types of synthetic cor-\nruption:\n\u2022Label noise : Training labels are randomly flipped to in-\ncorrect classes at rates of 0.2, 0.5, and 0.8, simulating\nincreasing levels of annotation errors.\n\u2022Input modifications : Images undergo three distinct\ntransformation categories:\n\u2013Strong geometric transformations that significantly dis-\ntort digit shapes, compromising semantic identity\n\u2013Additive Gaussian noise that introduces visual interfer-\nence while preserving underlying digit structure\u2013Mild augmentations (light warping, small-angle rota-\ntions, moderate scaling) that simulate natural variations\n3.2. Results\nLower MI values correspond to noisy points in the dis-\ntribution.\nWe first investigate how mutual information (MI) scores\nrespond to increasing label noise. Figure 1 shows this re-\nlationship across different noise levels. Panel (a) displays\nthe original MI distribution without noise. We then intro-\nduce label noise by randomly flipping labels at rates of 0.2,\n0.5, and 0.8. As the noise level increases from 0.2 to 0.5,\nthe MI score of the distribution decreases dramatically from\n1.22 to 0.53, indicating weakened statistical dependency be-\ntween inputs and their corrupted labels. More importantly,\nwe observe that mislabeled points consistently exhibit neg-\native MI values in 2, effectively separating them from cor-\nrectly labeled samples. This clear separation enables our\nmethod to both quantify the overall noise level in a dataset\nand identify individual noisy points, providing a foundation\nfor filtering corrupted samples during model training in sub-\nsequent sections.\nFiltering harmful noise improves model performance.\nWe evaluate several data selection strategies for model\ntraining, as illustrated in Figure 2(b). These strategies in-\nclude selecting the top, middle, or bottom-ranked samples\nby MI score, applied either globally across the entire dataset\nor within each class. As expected, selecting high-MI sam-\nples leads to improved test accuracy, since these data points\nexhibit stronger mutual dependency between images and\nlabels, indicating they are more likely to be correctly an-\nnotated and semantically aligned. Conversely, training on\nlow-MI samples results in sharp accuracy drops, confirm-\ning their detrimental impact on classification. Notably,\nclass-wise selection\u2014ranking samples by MI within each\nclass\u2014yields more stable performance across varying re-\ntention ratios, as it preserves class balance during selection.\nThis advantage becomes particularly important in low-data\n\n--- Page 4 ---\n(a) (b) (c)Figure 3. Evaluation under strong geometric distortions (random affine transformations). (a) Example pairs of clean and warped digit\nimages with significant structural deformation. (b) Mutual information scores plotted by class label. (c) Test accuracy as a function of\nretained training data, comparing MI-based selection and random sampling strategies.\nregimes or when dealing with imbalanced datasets. When\nnoise levels are relatively low, models trained on the full\ndataset already achieve high accuracy, and our MI-based fil-\ntering maintains this performance even when reducing the\ntraining set size. Under higher corruption levels, however,\nMI-based selection significantly outperforms random selec-\ntion in both accuracy and stability, demonstrating its robust-\nness in identifying trustworthy training examples.\nMI distinguishes semantic-altering modifications from\nbenign variations.\nWhile previous experiments focus on label noise, un-\nderstanding how MI responds to different types of input\nmodifications is also important. In real-world settings, im-\nages naturally exhibit variations due to collection condi-\ntions, compression artifacts, or environmental factors. We\ntherefore investigate whether MI can differentiate between\nmodifications that alter semantic content versus those that\npreserve it.\nWe examine three distinct categories of input modifi-\ncations: (1) strong geometric transformations that funda-\nmentally alter digit identity, (2) additive Gaussian noise\nthat overlays visual interference, and (3) mild augmenta-\ntions including scaling and rotation that preserve digit struc-\nture. These transformations are applied to randomly se-\nlected training samples while keeping labels unchanged.\nOur results reveal a clear dichotomy in MI\u2019s response.\nStrong geometric transformations (Fig. 3) that distort dig-\nits beyond recognition consistently produce low MI scores,\ndemonstrating that MI correctly identifies when semantic\ninformation has been compromised. These transformations\neffectively break the meaningful connection between the vi-\nsual input and its label, which MI captures through drasti-\ncally reduced scores.\nConversely, modifications that preserve semantic con-\ntent yield markedly different results. Images with Gaus-\nsian noise (Fig. 4) or mild augmentations (Fig. 5)\u2014despite\nvisible changes to appearance\u2014maintain stable MI scores.This stability occurs because these modifications, while al-\ntering surface-level features, leave the core digit identity in-\ntact. The preserved semantic structure ensures that the mu-\ntual information between input and label remains high.\nThis discriminative behavior addresses a critical con-\ncern: could MI-based selection inadvertently filter out use-\nful training variations? Modern training pipelines rely heav-\nily on data augmentation for improved generalization. Our\nfindings demonstrate that MI exhibits precisely the selec-\ntivity needed\u2014it flags inputs where semantic meaning is\ngenuinely compromised while accepting those with benign\nvariations. This makes MI-based selection not only com-\npatible with but complementary to standard augmentation\nstrategies, as it filters truly problematic samples while pre-\nserving beneficial diversity in the training data.\n4. Related Work\nData quality remains a critical challenge in machine learn-\ning, particularly when training datasets suffer from la-\nbel noise (randomly flipped labels) or input noise (e.g.,\nGaussian perturbations, occlusions, affine warping). La-\nbel noise disrupts the semantic alignment between inputs\nand targets, while input noise degrades feature integrity\nthrough transformations like blurring or geometric distor-\ntions. Real-world datasets exhibit concerning contamina-\ntion rates, ranging from 8.0% in ANIMAL-10N to 38.5%\nin Clothing1M [17, 19, 33, 41]. These imperfections de-\ngrade model performance and generalization, as DNNs can\nmemorize even completely random labels [45], necessitat-\ning robust strategies for identifying reliable training sam-\nples [5, 49].\nPrior work has explored three dominant paradigms for\nhandling noisy labels: loss correction, sample selection,\nand regularization. Loss correction techniques such as for-\nward/backward loss correction [28], Gold loss correction\n[9], and symmetric cross-entropy [36] modify loss func-\ntions to account for noise transition matrices. Recent ad-\n\n--- Page 5 ---\n(a) (b) (c)Figure 4. Evaluation under additive Gaussian noise (noise factor = 0.9). (a) Pairs of clean and noisy digit images, with semantic content\npreserved despite high pixel-level corruption. (b) MI score distribution across labels. (c) Accuracy curves for various data selection\nmethods across different retention levels.\n(a) (b) (c)\nFigure 5. Evaluation under mild geometric transformations (e.g., rotation, scaling, and affine distortion). (a) Representative examples of\noriginal versus transformed digit images. (b) MI score distribution across digit classes after applying input-level transformations. Red\ncrosses denote samples with corrupted labels. (c) Test accuracy under different sample selection strategies as a function of retention ratio.\nvances like T-Revision [38] operate without anchor points,\nwhile Dual-T [43] factorizes the transition matrix for im-\nproved estimation. However, these require accurate esti-\nmation of noise patterns, which is often infeasible in real-\nworld scenarios with complex or instance-dependent noise\n[3]. Sample selection methods like MentorNet [12], Co-\nteaching [7], and DivideMix [18] use auxiliary networks\nor small-loss criteria to filter noisy samples during train-\ning, exploiting the memorization effect where DNNs learn\nclean patterns before fitting noise [2]. SELFIE [33] iden-\ntifies refurbishable samples through prediction consistency.\nInfluence functions identify impactful training points by es-\ntimating how model predictions change with sample modi-\nfication [13] and can be applied to noisy data filtering [35].\nIt has been found that to change a prediction, the number\nof training data points to relabel is related to the noise ra-\ntio in the training set [42]. While effective, they rely on\nmodel gradients or loss dynamics, limiting their applicabil-\nity to specific architectures and optimization settings. Reg-\nularization approaches such as Mixup [46], label smooth-\ning [22, 37], and robust early-learning [39] impose induc-\ntive biases to reduce overfitting to noisy labels. Pre-training\nprovides robust initialization [10], while early stopping pre-vents noise memorization [20]. However, these techniques\nmay inadvertently suppress discriminative features in clean\ndata and often fail under severe label corruption [34]. Our\nwork introduces a complementary paradigm: MI-based data\nfiltering, which bypasses reliance on loss dynamics, noise\ntransition matrices, or architectural priors. Unlike gradient-\ndependent methods, our approach operates directly on the\ninput-label dependency structure, enabling model-agnostic\nnoise detection.\nMutual information has proven effective for data selec-\ntion across diverse machine learning contexts. Mak et al.\n[23] propose MI-based stratified sampling combined with\nsupport points to address class imbalance, achieving over\n80% data reduction while preserving classification accu-\nracy through representative subset selection. Similarly,\nKothawade et al. [14] leverage submodular mutual infor-\nmation functions for targeted data subset selection, demon-\nstrating 20-30% accuracy gains when selecting samples that\nalign with specific target distributions. In the context of\nGaussian Processes, Zainudin et al. [44] employ MI to itera-\ntively select informative data points for people tracking, us-\ning the Mahalanobis distance to determine when new obser-\nvations provide additional information beyond the current\n\n--- Page 6 ---\nmodel. Recent work has also explored MI for robust loss\nfunctions [6, 48] and meta-learning approaches [32], though\nthese require specific architectural modifications or clean\nvalidation data. These works establish MI as a principled\ncriterion for data selection, focusing primarily on computa-\ntional efficiency, class balance, or domain-specific applica-\ntions. Hejna et al. [8] utilize mutual information to priori-\ntize trajectories with higher dependency between states and\nactions, thereby improving performance in robot training\ntasks. Our work extends this line of research by demonstrat-\ning that MI-based selection can effectively distinguish be-\ntween clean and noisy samples, providing a unified frame-\nwork for data quality assessment that complements existing\nselection strategies.\nOur work distinguishes itself through three distinct con-\ntributions. First, we adapt the KSG estimator [8, 15]\nto compute pointwise MI contributions (Section 3.2) for\nfine-grained identification of noisy samples without requir-\ning labeled validation data or model retraining. Second,\nwe demonstrate MI\u2019s robustness to hybrid noise scenar-\nios (simultaneous label and input noise), a critical advan-\ntage over methods addressing either noise type in isolation\n[1, 7, 12, 46]. Third, unlike existing approaches that require\nnoise rate estimation [7, 33] or transition matrix computa-\ntion [28, 43], our method operates without prior knowledge\nof noise characteristics, making it practical for real-world\ndeployment where such information is unavailable.\n5. Conclusion\nIn this work, we propose a data selection method based\non mutual information (MI) between inputs and labels of\ndata. The method attribute MI scores to individual data\npoints, and filter out samples with low MI attribution rel-\native to the distribution. Empirical results show that lower\nMI scores effectively identify corrupted or mislabeled sam-\nples, distinguishing them from clean, semantically aligned\ndata. In noisy settings, selecting high-MI-attribution points\nimproves model accuracy compared to random sampling.\nIn addition, we find that MI remains robust to benign visual\nnoise added to input images , which does not alter their se-\nmantic meaning, and specifically flags truly uninformative\nor misleading inputs.\nAs a first step, our current study is limited to logistic\nregression models and MNIST dataset. Future work will\nexplore the extension of this framework to more complex\nmodels and benchmarks such as CIFAR-10 and TinyIm-\nageNet. We will also include comparisons with stronger\nbaselines.\nReferences\n[1] Eric Arazo, Diego Ortego, Paul Albert, Noel E O\u2019Connor,\nand Kevin McGuinness. Unsupervised label noise modeling\nand loss correction. In Proc. ICML , 2019. 6[2] Devansh Arpit, Stanislaw Jastrzebski, Nicolas Ballas, David\nKrueger, Emmanuel Bengio, Maxinder S Kanwal, Tegan\nMaharaj, Asja Fischer, Aaron Courville, Yoshua Bengio,\net al. A closer look at memorization in deep networks. In\nProc. ICML , pages 233\u2013242, 2017. 5\n[3] Pengfei Chen, Junjie Ye, Guangyong Chen, Jingwei Zhao,\nand Pheng-Ann Heng. Beyond class-conditional assumption:\nA primary attempt to combat instance-dependent label noise.\nInProc. AAAI , 2021. 5\n[4] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina\nToutanova. BERT: Pre-training of deep bidirectional trans-\nformers for language understanding. In Proc. ACL , pages\n4171\u20134186, 2019. 1\n[5] Beno \u02c6\u0131t Fr\u00b4enay and Michel Verleysen. Classification in the\npresence of label noise: A survey. IEEE Transaction on Neu-\nral Networks and Learning Systems , 25(5):845\u2013869, 2013. 1,\n4\n[6] Aritra Ghosh, Himanshu Kumar, and PS Sastry. Robust loss\nfunctions under label noise for deep neural networks. In\nProc. AAAI , 2017. 6\n[7] Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao\nXu, Weihua Hu, Ivor Tsang, and Masashi Sugiyama. Co-\nteaching: Robust training of deep neural networks with ex-\ntremely noisy labels. In Proc. NeurIPS , pages 8527\u20138537,\n2018. 1, 5, 6\n[8] Joey Hejna, Suvir Mirchandani, Ashwin Balakrishna, An-\nnie Xie, Ayzaan Wahid, Jonathan Tompson, Pannag Sanketi,\nDhruv Shah, Coline Devin, and Dorsa Sadigh. Robot data\ncuration with mutual information estimators. arXiv preprint\narXiv:2502.08623 , 2025. 1, 3, 6\n[9] Dan Hendrycks, Mantas Mazeika, Duncan Wilson, and\nKevin Gimpel. Using trusted data to train deep networks\non labels corrupted by severe noise. In Proc. NeurIPS , pages\n10456\u201310465, 2018. 4\n[10] Dan Hendrycks, Kimin Lee, and Mantas Mazeika. Using\npre-training can improve model robustness and uncertainty.\nInProc. ICML , 2019. 5\n[11] Jeremy Howard and Sebastian Ruder. Universal language\nmodel fine-tuning for text classification. In Proc. ACL , pages\n328\u2013339, 2018. 1\n[12] Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and\nLi Fei-Fei. MentorNet: Learning data-driven curriculum\nfor very deep neural networks on corrupted labels. In Proc.\nICML , 2018. 1, 5, 6\n[13] Pang Wei Koh and Percy Liang. Understanding black-box\npredictions via influence functions. In International confer-\nence on machine learning , pages 1885\u20131894. PMLR, 2017.\n5\n[14] Suraj Kothawade, Vishal Kaushal, Ganesh Ramakrishnan,\nJeff Bilmes, and Rishabh Iyer. Submodular mutual infor-\nmation for targeted data subset selection. arXiv preprint\narXiv:2105.00043 , 2021. 5\n[15] Alexander Kraskov, Harald St \u00a8ogbauer, and Peter Grass-\nberger. Estimating mutual information. Physical Review\nE\u2014Statistical, Nonlinear, and Soft Matter Physics , 69(6):\n066138, 2004. 1, 2, 6\n\n--- Page 7 ---\n[16] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.\nImageNet classification with deep convolutional neural net-\nworks. In Proc. NeurIPS , pages 1097\u20131105, 2012. 1\n[17] Kuang-Huei Lee, Xiaodong He, Lei Zhang, and Linjun\nYang. CleanNet: Transfer learning for scalable image clas-\nsifier training with label noise. In Proc. CVPR , pages 5447\u2013\n5456, 2018. 1, 4\n[18] Junnan Li, Richard Socher, and Steven CH Hoi. DivideMix:\nLearning with noisy labels as semi-supervised learning. In\nProc. ICLR , 2020. 1, 5\n[19] Wen Li, Limin Wang, Wei Li, Eirikur Agustsson, and Luc\nVan Gool. Webvision database: Visual learning and under-\nstanding from web data. arXiv preprint arXiv:1708.02862 ,\n2017. 1, 4\n[20] Sheng Liu, Jonathan Niles-Weed, Narges Razavian, and Car-\nlos Fernandez-Granda. Early-learning regularization pre-\nvents memorization of noisy labels. In Proc. NeurIPS , 2020.\n5\n[21] Ricardo V Lloyd, Lori A Erickson, Mary B Casey, King Y\nLam, Christine M Lohse, Sylvia L Asa, John KC Chan,\nRonald A DeLellis, H Ruben Harach, Kennichi Kakudo,\net al. Observer variation in the diagnosis of follicular vari-\nant of papillary thyroid carcinoma. The American Journal of\nSurgical Pathology , 28(10):1336\u20131340, 2004. 1\n[22] Michal Lukasik, Srinadh Bhojanapalli, Aditya Menon, and\nSanjiv Kumar. Does label smoothing mitigate label noise?\nInProc. ICLR , pages 6448\u20136458, 2020. 5\n[23] Alex Mak, Shubham Sahoo, Shivani Pandey, Yidan Yue, and\nLinglong Kong. Statistical undersampling with mutual infor-\nmation and support points. arXiv preprint arXiv:2412.14527 ,\n2024. 5\n[24] Winter Mason and Siddharth Suri. Conducting behavioral\nresearch on amazon\u2019s mechanical turk. Behavior Research\nMethods , 44(1):1\u201323, 2012. 1\n[25] Kezban Dilek Onal, Ye Zhang, Ismail Sengor Altingovde,\nMd Mustafizur Rahman, Pinar Karagoz, Alex Braylan, Bran-\ndon Dang, Heng-Lu Chang, Henna Kim, Quinten McNa-\nmara, et al. Neural information retrieval: At the end of\nthe early years. Information Retrieval Journal , 21(2-3):111\u2013\n182, 2018. 1\n[26] Liang Pang, Yanyan Lan, Jiafeng Guo, Jun Xu, Jingfang Xu,\nand Xueqi Cheng. Deeprank: A new deep architecture for\nrelevance ranking in information retrieval. In Proc. CIKM ,\npages 257\u2013266, 2017. 1\n[27] Gabriele Paolacci, Jesse Chandler, and Panagiotis G Ipeiro-\ntis. Running experiments on amazon mechanical turk. Judg-\nment and Decision Making , 5(5):411\u2013419, 2010. 1\n[28] Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon,\nRichard Nock, and Lizhen Qu. Making deep neural networks\nrobust to label noise: A loss correction approach. In Proc.\nCVPR , pages 1944\u20131952, 2017. 1, 4, 6\n[29] Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali\nFarhadi. You only look once: Unified, real-time object de-\ntection. In Proc. CVPR , pages 779\u2013788, 2016. 1\n[30] Aliaksei Severyn and Alessandro Moschitti. Twitter senti-\nment analysis with deep convolutional neural networks. In\nProc. ACL , pages 959\u2013962, 2015. 1[31] C. E. Shannon. A mathematical theory of communication.\nThe Bell System Technical Journal , 27(3):379\u2013423, 1948. 1\n[32] Jun Shu, Qi Xie, Lixuan Yi, Qian Zhao, Sanping Zhou,\nZongben Xu, and Deyu Meng. Meta-Weight-Net: Learning\nan explicit mapping for sample weighting. In Proc. NeurIPS ,\npages 1917\u20131928, 2019. 6\n[33] Hwanjun Song, Minseok Kim, and Jae-Gil Lee. SELFIE:\nRefurbishing unclean samples for robust deep learning. In\nProc. ICML , pages 5907\u20135915, 2019. 1, 4, 5, 6\n[34] Hwanjun Song, Minseok Kim, Dongmin Park, Yooju Shin,\nand Jae-Gil Lee. Learning from noisy labels with deep neural\nnetworks: A survey. IEEE transactions on neural networks\nand learning systems , 34(11):8135\u20138153, 2022. 1, 5\n[35] Stefano Teso, Andrea Bontempelli, Fausto Giunchiglia, and\nAndrea Passerini. Interactive label cleaning with example-\nbased explanations. Advances in Neural Information Pro-\ncessing Systems , 34:12966\u201312977, 2021. 5\n[36] Yisen Wang, Xingjun Ma, Zaiyi Chen, Yuan Luo, Jinfeng\nYi, and James Bailey. Symmetric cross entropy for robust\nlearning with noisy labels. In Proc. ICCV , pages 322\u2013330,\n2019. 1, 4\n[37] Jiaheng Wei, Hangyu Liu, Tongliang Liu, Gang Niu,\nMasashi Sugiyama, and Yang Liu. To smooth or not?\nwhen label smoothing meets noisy labels. arXiv preprint\narXiv:2106.04149 , 2021. 5\n[38] Xiaobo Xia, Tongliang Liu, Nannan Wang, Bo Han, Chen\nGong, Gang Niu, and Masashi Sugiyama. Are anchor\npoints really indispensable in label-noise learning? In Proc.\nNeurIPS , 2019. 5\n[39] Xiaobo Xia, Tongliang Liu, Bo Han, Chen Gong, Nannan\nWang, Zongyuan Ge, and Yi Chang. Robust early-learning:\nHindering the memorization of noisy labels. In Proc. ICLR ,\n2021. 5\n[40] Han Xiao, Huang Xiao, and Claudia Eckert. Adversarial la-\nbel flips attack on support vector machines. In Proc. ECAI ,\npages 870\u2013875, 2012. 1\n[41] Tong Xiao, Tian Xia, Yi Yang, Chang Huang, and Xiaogang\nWang. Learning from massive noisy labeled data for image\nclassification. In Proc. CVPR , pages 2691\u20132699, 2015. 1, 4\n[42] Jinghan Yang, Linjie Xu, and Lequan Yu. Relabeling min-\nimal training subset to flip a prediction. arXiv preprint\narXiv:2305.12809 , 2023. 5\n[43] Yu Yao, Tongliang Liu, Bo Han, Mingming Gong, Jiankang\nDeng, Gang Niu, and Masashi Sugiyama. Dual T: Reducing\nestimation error for transition matrix in label-noise learning.\nInProc. NeurIPS , 2020. 5, 6\n[44] Zulkarnain Zainudin, Sarath Kodagoda, and LV Nguyen.\nMutual information based data selection in gaussian pro-\ncesses for people tracking. In Proc. Australian Confer-\nence on Robotics and Automation, Wellington, New Zealand ,\n2012. 5\n[45] Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin\nRecht, and Oriol Vinyals. Understanding deep learning re-\nquires rethinking generalization. In Proc. ICLR , 2017. 1,\n4\n[46] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and\nDavid Lopez-Paz. mixup: Beyond empirical risk minimiza-\ntion. arXiv preprint arXiv:1710.09412 , 2017. 5, 6\n\n--- Page 8 ---\n[47] Weinan Zhang, Tianming Du, and Jun Wang. Deep learning\nover multi-field categorical data. In Proc. ECIR , pages 45\u2013\n57, 2016. 1\n[48] Zhilu Zhang and Mert Sabuncu. Generalized cross entropy\nloss for training deep neural networks with noisy labels. In\nProc. NeurIPS , pages 8778\u20138788, 2018. 1, 6\n[49] Xingquan Zhu and Xindong Wu. Class noise vs. attribute\nnoise: A quantitative study. Artificial Intelligence Review ,\n22(3):177\u2013210, 2004. 4",
  "project_dir": "artifacts/projects/enhanced_stat.ML_2508.07713v1_Detecting_Mislabeled_and_Corrupted_Data_via_Pointw",
  "communication_dir": "artifacts/projects/enhanced_stat.ML_2508.07713v1_Detecting_Mislabeled_and_Corrupted_Data_via_Pointw/.agent_comm",
  "assigned_at": "2025-08-12T21:01:48.504632",
  "status": "assigned"
}